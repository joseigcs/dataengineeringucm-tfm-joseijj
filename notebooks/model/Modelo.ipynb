{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Modelaje de datos\r\n",
        "En esta notebook realizaremos el modelo final con los datos resultantes de la capa Gold. En este caso es para el activo financiero Apple.Esta notebook debe ser ejecutada en Azure Synapse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Parameters\n",
        "asset = 'apple'   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "storage_account_name = 'nticmasterstg' \r\n",
        "data_lake_container = f'abfss://datalake@{storage_account_name}.dfs.core.windows.net' \r\n",
        "gold_folder = 'gold' # Directorio final\r\n",
        "\r\n",
        "gold_table_path = f\"{data_lake_container}/{gold_folder}/{asset}\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import pickle\r\n",
        "from azure.storage.blob import BlobServiceClient, ContainerClient\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\r\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Carga de datos\n",
        "data = spark.read.format(\"delta\").load(gold_table_path)\n",
        "data = data.toPandas()\n",
        "\n",
        "# Aplicar la transformación logarítmica\n",
        "data['Log_Volume'] = np.log(data['Volume'])\n",
        "data['Log_Adj_Close'] = np.log(data['Adj_Close'])\n",
        "data['Log_7_day_moving_avg'] = np.log(data['7_day_moving_avg'])\n",
        "data['Log_30_day_moving_avg'] = np.log(data['30_day_moving_avg'])\n",
        "\n",
        "# Creamos variables laggeadas\n",
        "for lag in range(1, 4):\n",
        "    data[f'Log_Adj_Close_Lag{lag}'] = data['Log_Adj_Close'].shift(lag)\n",
        "    data[f'Log_Volume_Lag{lag}'] = data['Log_Volume'].shift(lag)\n",
        "    data[f'Log_7_day_moving_avg_Lag{lag}'] = data['Log_7_day_moving_avg'].shift(lag)\n",
        "    data[f'Log_30_day_moving_avg_Lag{lag}'] = data['Log_30_day_moving_avg'].shift(lag)\n",
        "    data[f'daily_return_Lag{lag}'] = data['daily_return'].shift(lag)\n",
        "\n",
        "data = data.dropna()\n",
        "\n",
        "features = ['Log_Adj_Close_Lag1', 'Log_Volume_Lag1', \n",
        "            'Log_7_day_moving_avg_Lag1',  \n",
        "            'daily_return_Lag1',  \n",
        "            'Three_Component_Index',\n",
        "            'year', 'month',\n",
        "             'monthly_close', 'monthly_volume']\n",
        "\n",
        "X = data[features]\n",
        "y = data['Log_Adj_Close']\n",
        "\n",
        "# Escalamos datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Introducimos el Modelo Ridge con ajuste de alpha\n",
        "alphas = np.logspace(-4, 4, 10)\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': alphas}\n",
        "\n",
        "# Búsqueda de los mejores hiperparámetros (ajuste de alpha)\n",
        "ridge_cv = GridSearchCV(ridge, parameters, cv=tscv)\n",
        "ridge_cv.fit(X_scaled, y)\n",
        "\n",
        "# Imprimir el mejor valor de alpha encontrado\n",
        "print(f'Mejor valor de alpha: {ridge_cv.best_params_[\"alpha\"]}')\n",
        "\n",
        "# Usar el mejor modelo con el mejor alpha\n",
        "best_model = ridge_cv.best_estimator_\n",
        "\n",
        "# Evaluación del modelo\n",
        "for train_index, test_index in tscv.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    \n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    \n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "    print(f'Mean Absolute Error: {mae}')\n",
        "    print(f'R^2 Score: {r2}')\n",
        "\n",
        "# Imprimimos los coeficientes del modelo\n",
        "coefficients = pd.DataFrame(best_model.coef_, X.columns, columns=['Coefficient'])\n",
        "print(coefficients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Exportar el modelo en formato pkl, de forma que quede registrado\r\n",
        "\r\n",
        "model_bytes = pickle.dumps(best_model)\r\n",
        "\r\n",
        "# BlobServiceClient a partir de la cadena de conexión (la he quitado ahora)\r\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=nticmasterstg;AccountKey=6aC6DUKYom+4R7dqYsuKKbsqN18Goyj6TlD5pOQIUTTxfyn61nduW9XSgAWeOpUvsEfKBYosnUZp+ASt8hU/sw==;EndpointSuffix=core.windows.net\"\r\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\r\n",
        "\r\n",
        "# Cliente del contenedor de Azure Blob Storage\r\n",
        "container_name = \"datalake\"\r\n",
        "container_client = blob_service_client.get_container_client(container_name)\r\n",
        "\r\n",
        "blob_name = \"/resources/apple_ridge_model.pkl\" \r\n",
        "blob_client = container_client.get_blob_client(blob_name)\r\n",
        "\r\n",
        "# Subo el archivo pickle serializado al Blob Storage\r\n",
        "blob_client.upload_blob(model_bytes, overwrite=True)\r\n",
        "\r\n",
        "print(\"Modelo subido exitosamente a Azure Blob Storage\")\r\n",
        ""
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}